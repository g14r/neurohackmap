{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuromap Project Neurohackademy 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install libraries/ set up script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"neuromap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the defaults for viewing the dataframe\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify missing values\n",
    "missing_values = [\"  \", \"-\"]\n",
    "df = pd.read_csv('NeuroMap-38responses.csv', na_values = missing_values, encoding='latin-1')\n",
    "\n",
    "#view data\n",
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clean data\n",
    "# # rename column questions to shorter\n",
    "df.columns = ['timestamp','consent','name','birthplace','birth_year', 'gender',\n",
    "              'undergrad_deg','undergrad_loc',  'undergrad_inst','undergrad_research',\n",
    "              'ra_qual','ra_lm_loc', 'ra_lm_inst', 'ra_lm_research',\n",
    "              'masters_qual','masters_loc', 'masters_inst', 'masters_research', \n",
    "              'phd_qual','phd_loc', 'phd_inst', 'phd_research',\n",
    "              'post_doc_qual', 'postdoc_loc' ,'postdoc_inst','postdoc_research', \n",
    "            'faculty_qual', 'faculty_loc', 'faculty_inst', 'faculty_research',\n",
    "              'google_scholar']\n",
    "\n",
    "# change white spaces (blanks) to NaN\n",
    "#df.replace(r'^\\s+$', np.nan, regex=True)\n",
    "\n",
    "replace_dict_undergrad = {\n",
    "    \"Tijuana, Baja California, MÌ©xico\": \"Tijuana, Baja California, Mexico\",\n",
    "    'Raleigh & Chapel Hill, North Carolina, USA': 'Chapel Hill, North Carolina, USA'\n",
    "}\n",
    "df['undergrad_loc'] = df['undergrad_loc'].replace(replace_dict_undergrad) \n",
    "\n",
    "replace_dict_research = {\n",
    "    'Central Institute of Chemistry and Mechanics': 'Nagatinskaya, Moscow, Russia'\n",
    "}\n",
    "df['ra_lm_loc'] = df['ra_lm_loc'].replace(replace_dict_research)\n",
    "\n",
    "replace_dict_phd = {\n",
    "    'Rio de Janeiro, Brazil AND Montreal, Canada': 'Rio de Janeiro, Brazil'\n",
    "}\n",
    "df['phd_loc'] = df['phd_loc'].replace(replace_dict_phd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loop through rows to get the longitude and latitude of the hometowns\n",
    "lat=[]\n",
    "long=[]\n",
    "for home_location in df.loc[:,\"birthplace\"]:\n",
    "    location_1 = geolocator.geocode(home_location, timeout=10)\n",
    "    #print((location_1.latitude, location_1.longitude))\n",
    "    \n",
    "    lat.append(location_1.latitude)\n",
    "    long.append(location_1.longitude)\n",
    "\n",
    "#Saving lat and long in separate columns in the dataframe    \n",
    "df['HometownLatitude'] = lat\n",
    "df['HometownLatitude'] = df['HometownLatitude'].astype('float')\n",
    "\n",
    "df['HometownLongitude'] = long\n",
    "df['HometownLongitude'] = df['HometownLongitude'].astype('float')\n",
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through rows to get the longitude and latitude of the undergrad_cities (be aware of missing data)\n",
    "lat_list = []\n",
    "long_list = []\n",
    "for undergrad_location in df['undergrad_loc']:\n",
    "    #print(location_1)\n",
    "    \n",
    "    if pd.isnull(undergrad_location):\n",
    "        lat2 = None\n",
    "        long2 = None\n",
    "    else:\n",
    "        location_1 = geolocator.geocode(undergrad_location, timeout=10)\n",
    "        if location_1 is None:\n",
    "            raise ValueError(\"Geocode failed\")\n",
    "        lat2 = location_1.latitude\n",
    "        long2 = location_1.longitude\n",
    "    \n",
    "    lat_list.append(lat2)\n",
    "    long_list.append(long2)\n",
    "    #print((lat,long,location))\n",
    "        \n",
    "# #Saving lat and long in separate columns in the dataframe    \n",
    "df['UndergradLatitude' ] = lat_list\n",
    "df['UndergradLatitude'] = df['UndergradLatitude'].astype('float')\n",
    "\n",
    "df['UndergradLongitude'] = long_list\n",
    "df['UndergradLongitude'] = df['UndergradLongitude'].astype('float')\n",
    "#df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map with undergrad locations\n",
    "df_undergrad = df.loc[:,\"UndergradLatitude\":\"UndergradLongitude\"] #create a subset of df to deal with the na problem\n",
    "df_undergrad = df_undergrad.dropna()\n",
    "undergrad_locs = df.loc[:,\"undergrad_loc\"]\n",
    "#print(df_undergrad)\n",
    "\n",
    "if None in lat_list: lat_list.remove(None)\n",
    "if None in long_list: long_list.remove(None)\n",
    "undergrad_locs = [x for x in undergrad_locs if pd.notna(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41.3082138, -72.9250518, 'New Haven, CT, USA')\n",
      "(None, None, nan)\n",
      "(-37.8142176, 144.9631608, 'Melbourne, Victoria, Australia')\n",
      "(52.4775396, -1.894053, 'Birmingham, UK')\n",
      "(39.9527237, -75.1635262, 'Philadelphia, PA, USA')\n",
      "(None, None, nan)\n",
      "(-34.6075616, -58.437076, 'Buenos Aires, Argentina')\n",
      "(55.6828925, 37.6223775, 'Nagatinskaya, Moscow, Russia')\n",
      "(39.9527237, -75.1635262, 'Philadelphia, USA')\n",
      "(40.7127281, -74.0060152, 'New York City, New York, USA')\n",
      "(None, None, nan)\n",
      "(None, None, nan)\n",
      "(25.0375198, 121.5636796, 'Taipei, Taiwan')\n",
      "(None, None, nan)\n",
      "(40.7127281, -74.0060152, 'New York, NY')\n",
      "(None, None, nan)\n",
      "(None, None, nan)\n",
      "(None, None, nan)\n",
      "(None, None, nan)\n",
      "(None, None, nan)\n",
      "(None, None, nan)\n",
      "(37.4443293, -122.1598465, 'Palo Alto, California, USA')\n",
      "(45.5202471, -122.6741949, 'Portland, OR, USA')\n",
      "(None, None, nan)\n",
      "(None, None, nan)\n",
      "(None, None, nan)\n",
      "(None, None, nan)\n",
      "(None, None, nan)\n",
      "(37.8708393, -122.2728639, 'Berkeley, CA, USA')\n",
      "(37.7792808, -122.4192363, 'San Francisco, CA, USA')\n",
      "(35.7006177, 51.4013785, 'Tehran, Tehran, Iran')\n",
      "(40.4416941, -79.9900861, 'Pittsburgh, PA, USA')\n",
      "(38.8950092, -77.0365625, 'Washington, DC, US')\n",
      "(None, None, nan)\n",
      "(52.5170365, 13.3888599, 'Berlin, Germany')\n",
      "(None, None, nan)\n",
      "(34.0536909, -118.2427666, 'Los Angeles, CA, USA')\n",
      "(None, None, nan)\n"
     ]
    }
   ],
   "source": [
    "# create RA locations \n",
    "# Loop through rows to get the longitude and latitude of the RA_locations (be aware of missing data)\n",
    "lat_list = []\n",
    "long_list = []\n",
    "for research_location in df['ra_lm_loc']:\n",
    "    #print(location_1)\n",
    "    \n",
    "    if pd.isnull(research_location):\n",
    "        lat = None\n",
    "        long = None\n",
    "    else:\n",
    "        location_1 = geolocator.geocode(research_location, timeout=10)\n",
    "        if location_1 is None:\n",
    "            raise ValueError(\"Geocode failed\")\n",
    "        lat = location_1.latitude\n",
    "        long = location_1.longitude\n",
    "    \n",
    "    lat_list.append(lat)\n",
    "    long_list.append(long)\n",
    "    print((lat,long,research_location))\n",
    "        \n",
    "# #Saving lat and long in separate columns in the dataframe    \n",
    "df['RA_LM_Latitude' ] = lat_list\n",
    "df['RA_LM_Latitude'] = df['RA_LM_Latitude'].astype('float')\n",
    "\n",
    "df['RA_LM_Longitude'] = long_list\n",
    "df['RA_LM_Longitude'] = df['RA_LM_Longitude'].astype('float')\n",
    "#df.head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a map with research position locations\n",
    "df_research = df.loc[:,\"RA_LM_Latitude\":\"RA_LM_Longitude\"] #create a subset of df to deal with the na problem\n",
    "df_research = df_research.dropna()\n",
    "research_locs = df.loc[:,\"ra_lm_loc\"]\n",
    "#print(df_undergrad)\n",
    "\n",
    "lat_list = list(filter(None, lat_list))\n",
    "long_list = list(filter(None, long_list))\n",
    "research_locs = [x for x in research_locs if pd.notna(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# research locations plotting \n",
    "research_map = folium.Map()\n",
    "#Loop through locations and add the markers on the map\n",
    "for research_location in range(len(research_locs)): \n",
    "    folium.Marker([lat_list[research_location], long_list[research_location]], popup=research_locs[research_location]).add_to(research_map)\n",
    "\n",
    "#display map\n",
    "#research_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40.4416941, -79.9900861, 'Pittsburgh, PA, USA')\n",
      "(45.886548, 11.0452369, 'Rovereto, Trentino, Italy')\n",
      "(-37.8142176, 144.9631608, 'Melbourne, Victoria, Australia')\n",
      "(52.4775396, -1.894053, 'Birmingham, UK')\n",
      "(39.9527237, -75.1635262, 'Philadelphia, PA, USA')\n",
      "(38.8950092, -77.0365625, 'Washington, DC')\n",
      "(50.1106444, 8.6820917, 'Frankfurt, Germany')\n",
      "(48.8566101, 2.3514992, 'Paris/France')\n",
      "(32.7174209, -117.1627714, 'San Diego, CA, USA')\n",
      "(40.3492744, -74.6592958, 'Princeton, NJ, USA')\n",
      "(47.6038321, -122.3300624, 'Seattle, WA, United States')\n",
      "(25.7742658, -80.1936589, 'Miami, FL, USA')\n",
      "(53.9590555, -1.0815361, 'York, UK')\n",
      "(53.550341, 10.000654, 'Hamburg, Germany')\n",
      "(40.4416941, -79.9900861, 'Pittsburgh, PA')\n",
      "(37.5666791, 126.9782914, 'Seoul, South Korea')\n",
      "(None, None, nan)\n",
      "(51.5073219, -0.1276474, 'London, United Kingdom')\n",
      "(52.1518157, 4.48110886662043, 'Leiden, the Netherlands')\n",
      "(42.3602534, -71.0582912, 'Boston, MA, USA')\n",
      "(34.4221319, -119.7026673, 'Santa Barbara, California, USA')\n",
      "(43.703622, -72.288666, 'Hanover, New Hampshire, USA')\n",
      "(35.5306348, -92.7907215, 'Austin, TX, USA')\n",
      "(-22.9110137, -43.2093727, 'Rio de Janeiro, Brazil')\n",
      "(38.6268039, -90.1994097, 'St. Louis, MO, USA')\n",
      "(31.778345, 35.2250786, 'Jerusalem, Israel')\n",
      "(39.1670396, -86.5342881, 'Bloomington, IN, USA')\n",
      "(45.886548, 11.0452369, 'Rovereto, Italy')\n",
      "(37.8708393, -122.2728639, 'Berkeley, CA, USA')\n",
      "(42.3602534, -71.0582912, 'Boston, MA USA')\n",
      "(51.4893335, -0.144055084527687, 'London, London, UK')\n",
      "(43.157285, -77.615214, 'Rochester, NY, USA')\n",
      "(38.8950092, -77.0365625, 'Washington, DC, US')\n",
      "(42.9537654, -81.2291529, 'London, Ontario, Canada')\n",
      "(37.8708393, -122.2728639, 'Berkeley, CA, USA')\n",
      "(42.3750997, -71.1056157, 'Cambridge, MA USA')\n",
      "(37.8708393, -122.2728639, 'Berkeley, CA, USA')\n",
      "(51.7520131, -1.2578499, 'Oxford, Oxfordshire, United Kingdom')\n"
     ]
    }
   ],
   "source": [
    "# create PHD/Doctoral locations \n",
    "# Loop through rows to get the longitude and latitude of the RA_locations (be aware of missing data)\n",
    "lat_list = []\n",
    "long_list = []\n",
    "for phd_location in df['phd_loc']:\n",
    "    #print(location_1)\n",
    "    \n",
    "    if pd.isnull(phd_location):\n",
    "        lat = None\n",
    "        long = None\n",
    "    else:\n",
    "        location_1 = geolocator.geocode(phd_location, timeout=10)\n",
    "        if location_1 is None:\n",
    "            raise ValueError(\"Geocode failed\")\n",
    "        lat = location_1.latitude\n",
    "        long = location_1.longitude\n",
    "    \n",
    "    lat_list.append(lat)\n",
    "    long_list.append(long)\n",
    "    print((lat,long,phd_location))\n",
    "        \n",
    "# #Saving lat and long in separate columns in the dataframe    \n",
    "df['PHD_Latitude' ] = lat_list\n",
    "df['PHD_Latitude'] = df['PHD_Latitude'].astype('float')\n",
    "\n",
    "df['PHD_Longitude'] = long_list\n",
    "df['PHD_Longitude'] = df['PHD_Longitude'].astype('float')\n",
    "#df.head(40)\n",
    "\n",
    "# create a map with research position locations\n",
    "df_phd = df.loc[:,\"PHD_Longitude\":\"PHD_Latitude\"] #create a subset of df to deal with the na problem\n",
    "df_phd = df_phd.dropna()\n",
    "phd_locs = df.loc[:,\"phd_loc\"]\n",
    "#print(df_undergrad)\n",
    "\n",
    "lat_list = list(filter(None, lat_list))\n",
    "long_list = list(filter(None, long_list))\n",
    "phd_locs = [x for x in phd_locs if pd.notna(x)]\n",
    "\n",
    "# research locations plotting \n",
    "phd_map = folium.Map()\n",
    "#Loop through locations and add the markers on the map\n",
    "for phd_location in range(len(phd_locs)): \n",
    "    folium.Marker([lat_list[phd_location], long_list[phd_location]], popup=phd_locs[phd_location]).add_to(phd_map)\n",
    "\n",
    "#display map    \n",
    "#phd_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b5741a0ceb4d5780ae1830c01cb717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(basemap={'url': 'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', 'max_zoom': 19, 'attribution': 'Map …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyleaflet as lf\n",
    "from ipyleaflet import (Map, basemaps, basemap_to_tiles, Circle, LayersControl, FullScreenControl)\n",
    "\n",
    "m = Map(zoom=1)\n",
    "\n",
    "# hometown\n",
    "hometown = []    \n",
    "for ii in range(len(df)):\n",
    "    coords = df.HometownLatitude[ii],df.HometownLongitude[ii]\n",
    "    c = Circle()\n",
    "    c.radius = 600\n",
    "    c.location = coords\n",
    "    c.color = 'blue'\n",
    "    c.fill = True\n",
    "    c.name = \"Hometown location\"\n",
    "    hometown.append(c)\n",
    "ht = lf.LayerGroup(name='hometown', layers=hometown)\n",
    "m.add_layer(ht)  \n",
    "\n",
    "# undergrad\n",
    "undergrad = []  \n",
    "for ii in range(len(df)):\n",
    "    coords = df.UndergradLatitude[ii],df.UndergradLongitude[ii]\n",
    "    c = Circle()\n",
    "    c.radius = 600\n",
    "    c.location = coords\n",
    "    c.color = 'green'\n",
    "    c.fill = True\n",
    "    c.name = \"Undergrad location\"\n",
    "    undergrad.append(c)\n",
    "ug = lf.LayerGroup(name='undergrad', layers=undergrad)\n",
    "m.add_layer(ug)\n",
    "\n",
    "# phd\n",
    "phd = []  \n",
    "for ii in range(len(df)):\n",
    "    coords = df.PHD_Latitude[ii],df.PHD_Longitude[ii]\n",
    "    c = Circle()\n",
    "    c.radius = 600\n",
    "    c.location = coords\n",
    "    c.color = 'red'\n",
    "    c.fill = True\n",
    "    c.name = \"PhD location\"\n",
    "    phd.append(c)\n",
    "p = lf.LayerGroup(name='phd', layers=phd)\n",
    "m.add_layer(p)\n",
    "m.add_control(LayersControl())\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
