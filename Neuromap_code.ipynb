{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuromap Project Neurohackademy 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install libraries/ set up script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"neurohackmap\")\n",
    "#! pip install ipyleaflet \n",
    "import ipyleaflet as lf\n",
    "from ipyleaflet import (Map, basemaps, basemap_to_tiles, Circle, CircleMarker, LayersControl,\n",
    "                        FullScreenControl, WidgetControl, Marker, Popup)\n",
    "from ipywidgets import (IntSlider, ColorPicker, jslink, HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the defaults for viewing the dataframe in the jupyter notebook\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define missing values\n",
    "missing_values = [\"  \", \"-\"]\n",
    "\n",
    "#load in the questionnaire response data from a csv file \n",
    "df = pd.read_csv('NeuroMap 2.csv', na_values = missing_values, encoding='latin-1')\n",
    "\n",
    "#optionally view the data\n",
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data cleaning steps \n",
    "## rename column questions to shorter\n",
    "df.columns = ['timestamp','consent','name','birthplace','birth_year', 'gender',\n",
    "              'undergrad_deg','undergrad_loc',  'undergrad_inst','undergrad_research',\n",
    "              'ra_qual','ra_lm_loc', 'ra_lm_inst', 'ra_lm_research',\n",
    "              'masters_qual','masters_loc', 'masters_inst', 'masters_research', \n",
    "              'phd_qual','phd_loc', 'phd_inst', 'phd_research',\n",
    "              'post_doc_qual', 'postdoc_loc' ,'postdoc_inst','postdoc_research', \n",
    "            'faculty_qual', 'faculty_loc', 'faculty_inst', 'faculty_research',\n",
    "              'google_scholar']\n",
    "\n",
    "## during code development, irregularities in input style that caused geopy errors were identified.\n",
    "## these have been manually corrected as per below\n",
    "replace_dict_birth = {\n",
    "    \"Tijuana, Baja California, MÌ©xico\": \"Tijuana, Baja California, Mexico\",\n",
    "    \"Ìävreux, Normandy, France\": \"Normandy, France\"\n",
    "}\n",
    "df['birthplace'] = df['birthplace'].replace(replace_dict_birth) \n",
    "\n",
    "\n",
    "replace_dict_undergrad = {\n",
    "    'Tijuana, Baja California, MÌ©xico': 'Tijuana, Baja California, Mexico',\n",
    "    'Raleigh & Chapel Hill, North Carolina, USA': 'Chapel Hill, North Carolina, USA'\n",
    "}\n",
    "df['undergrad_loc'] = df['undergrad_loc'].replace(replace_dict_undergrad) \n",
    "\n",
    "replace_dict_research = {\n",
    "    'Central Institute of Chemistry and Mechanics': 'Nagatinskaya, Moscow, Russia',\n",
    "    'Boston, MA & San Francisco, CA': 'San Francisco, CA'    \n",
    "}\n",
    "\n",
    "df['ra_lm_loc'] = df['ra_lm_loc'].replace(replace_dict_research)\n",
    "\n",
    "replace_dict_phd = {\n",
    "    'Rio de Janeiro, Brazil AND Montreal, Canada': 'Rio de Janeiro, Brazil'\n",
    "}\n",
    "df['phd_loc'] = df['phd_loc'].replace(replace_dict_phd) \n",
    "\n",
    "\n",
    "replace_dict_masters = {\n",
    "    'Neuroscience': 'Strasbourg, Alsace, France',\n",
    "    'Mexico city, MÌ©xico': 'Mexico city, Mexico'\n",
    "}\n",
    "df['masters_loc'] = df['masters_loc'].replace(replace_dict_masters)\n",
    "\n",
    "\n",
    "replace_dict_postdoc = {\n",
    "    'New Haven, CT, United States AND Durham, NC, United States': 'New Haven, CT, United States',\n",
    "    '1) York, UK; 2) Sussex, UK': 'York, UK',\n",
    "    'Seattle, WA and Cambridge, MA':'Seattle, WA'\n",
    "}\n",
    "df['postdoc_loc'] = df['postdoc_loc'].replace(replace_dict_postdoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The following code uses geopy to city, state, country information to get latitude and longitude\n",
    "# This is done for birth_location, undergrad_location, research position location, PhD location and \n",
    "# post doc location\n",
    "\n",
    "# Birth_location is done first\n",
    "# First create empty structures for your lat and long values\n",
    "lat_list = []\n",
    "long_list = []\n",
    "\n",
    "#loop through birthplace locations\n",
    "for birth_location in df['birthplace']:\n",
    "    #print(location_1)\n",
    "    \n",
    "    if pd.isnull(birth_location):\n",
    "        lat = None\n",
    "        long = None #this section is to manage missing data\n",
    "    else:\n",
    "        location_1 = geolocator.geocode(birth_location, timeout=10)\n",
    "        if location_1 is None:\n",
    "            raise ValueError(\"Geocode failed\") # this section is to manage data in wrong format\n",
    "        lat = location_1.latitude\n",
    "        long = location_1.longitude\n",
    "    \n",
    "    lat_list.append(lat)\n",
    "    long_list.append(long)\n",
    "    #print((lat,long,birth_location))\n",
    "        \n",
    "#Saving lat and long in separate columns in the dataframe    \n",
    "df['HometownLatitude'] = lat_list\n",
    "df['HometownLatitude'] = df['HometownLatitude'].astype('float')\n",
    "\n",
    "df['HometownLongitude'] = long_list\n",
    "df['HometownLongitude'] = df['HometownLongitude'].astype('float')\n",
    "df.head(20)\n",
    "\n",
    "#Get the column with hometown location\n",
    "locs = df.loc[:,\"birthplace\"]\n",
    "\n",
    "#Plot hometown locations on the map!\n",
    "birth_map = folium.Map()\n",
    "\n",
    "#Loop through locations and add the markers on the map\n",
    "for home_location in range(len(locs)): \n",
    "    folium.Marker([lat_list[home_location], long_list[home_location]], popup=locs[home_location]).add_to(birth_map)\n",
    "    \n",
    "# output the map\n",
    "#birth_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check your dataframe  \n",
    "#df.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.8239891, 45.886548, -34.4243941, 22.2793278, 42.2681569, 38.9719384, -34.6075616, 55.7504461, 18.9387711, 37.4443293, 40.4258686, 32.527002, 25.0375198, 29.8693496, 42.0128695, 37.5666791, 32.5010188, 52.1518157, 36.1556805, 33.5778631, 34.0536909, 33.7872568, -22.9110137, 45.421106, 31.778345, 35.9131542, 55.0282171, 29.9499323, 43.0821793, 35.7006177, 40.7127281, 38.8339578, 43.653963, 31.778345, 43.157285, 34.0966764, 51.4893335, 42.3602534, 43.703622, 51.4538022, 49.4404591, 43.6307863, 52.2646577, 52.9534161, 25.7742658, 52.1518157, 34.1476452, 41.5623178, 1.3408528, 52.266837, 42.6384261, 53.0758196, 39.2847494, 38.8950092]\n",
      "[-71.4128343, 11.0452369, 150.89385, 114.1628131, -83.7312291, -95.2359496, -58.437076, 37.6174943, 72.8353355, -122.1598465, -86.9080655, -85.4367484053398, 121.5636796, 77.8902124, -73.9081901, 126.9782914, -116.9646629, 4.48110886662043, -95.9929113, -101.8551665, -118.2427666, -117.8503088, -43.2093727, -75.690308, 35.2250786, -79.05578, 82.9234509, -90.0701156, -73.7853915, 51.4013785, -74.0060152, -104.8253485, -79.387207, 35.2250786, -77.615214, -117.7197785, -0.144055084527687, -71.0582912, -72.288666, -2.5972985, 1.0939658, -74.4659275, 10.5236066, -1.1492773, -80.1936589, 4.48110886662043, -118.1444779, -72.6509061, 103.878446863736, 8.049741, 12.674297, 8.8071646, -76.6204746396999, -77.0365625]\n",
      "['Providence, RI, USA', 'Rovereto, Trentino, Italy', 'Wollongong, NSW, Australia', 'Hong Kong', 'Ann Arbor, MI, USA', 'Lawrence, KS, United States', 'Buenos Aires, Argentina', 'Moscow/Russia', 'Mumbai, India', 'Palo Alto, CA, USA', 'West Lafayette, IN, United States', 'Auburn, AL, USA', 'Taipei, Taiwan', 'Roorkee, India', 'Annandale-on-Hudson, NY, USA', 'Seoul, South Korea', 'Tijuana, Baja California, Mexico', 'Leiden, the Netherlands', 'Tulsa, OK, USA', 'Lubbock, Texas, USA', 'Los Angeles, California, USA', 'Orange, CA, USA', 'Rio de Janeiro, Rio de Janeiro, Brazil', 'Ottawa, Canada', 'Jerusalem, Israel', 'Chapel Hill, North Carolina, USA', 'Novosibirsk, Russia', 'New Orleans, LA, USA', 'Saratoga Springs, NY, USA', 'Tehran, Tehran, Iran', 'New York, NY, USA', 'colorado springs, CO, US', 'Toronto, Ontario, Canada', 'Jerusalem, Israel', 'Rochester, NY . USA', 'Claremont, CA, USA', 'London, UK', 'Boston, MA', 'Hanover, NH, USA', 'Bristol, UK', 'Rouen, Normandy, France', 'Hamilton, NY, USA', 'Braunschweig, Niedersachsen, Germany ', 'Nottingham, England', 'Miami, Florida, USA', 'Leiden, the Netherlands', 'Pasadena, California, USA', 'Middletown, CT, USA', 'Singapore', 'Osnabrueck, Lower Saxony, Germany', 'Italy', 'Bremen, Germany', 'Baltimore, Maryland, USA', 'Washington DC, DC, USA']\n"
     ]
    }
   ],
   "source": [
    "# Undergrad location is done second\n",
    "# First create empty structures for your lat and long values\n",
    "lat_list = []\n",
    "long_list = []\n",
    "\n",
    "#loop through undergrad locations\n",
    "for undergrad_location in df['undergrad_loc']:\n",
    "    #print(location_1)\n",
    "    \n",
    "    if pd.isnull(undergrad_location):\n",
    "        lat = None\n",
    "        long = None\n",
    "    else:\n",
    "        location_1 = geolocator.geocode(undergrad_location, timeout=10)\n",
    "        if location_1 is None:\n",
    "            raise ValueError(\"Geocode failed\")\n",
    "        lat = location_1.latitude\n",
    "        long = location_1.longitude\n",
    "    \n",
    "    lat_list.append(lat)\n",
    "    long_list.append(long)\n",
    "    #print((lat,long,undergrad_location))\n",
    "        \n",
    "# #Saving lat and long in separate columns in the original dataframe    \n",
    "df['UndergradLatitude' ] = lat_list\n",
    "df['UndergradLatitude'] = df['UndergradLatitude'].astype('float')\n",
    "\n",
    "df['UndergradLongitude'] = long_list\n",
    "df['UndergradLongitude'] = df['UndergradLongitude'].astype('float')\n",
    "\n",
    "# because there are missing values which mean the mapping won't work you need to create a subset df\n",
    "\n",
    "#create a subset of df\n",
    "df_undergrad = df.loc[:,\"UndergradLatitude\":\"UndergradLongitude\"] \n",
    "df_undergrad = df_undergrad.dropna()\n",
    "\n",
    "# get undergrad locations \n",
    "undergrad_locs = df.loc[:,\"undergrad_loc\"]\n",
    "#print(df_undergrad)\n",
    "\n",
    "#modify lat_list and long_list to remove missing values\n",
    "lat_list = list(filter(None, lat_list))\n",
    "long_list = list(filter(None, long_list))\n",
    "undergrad_locs = [x for x in undergrad_locs if pd.notna(x)]\n",
    "\n",
    "# check formats are correct with the NA values removed\n",
    "print(lat_list)\n",
    "print(long_list)\n",
    "print(undergrad_locs)\n",
    "type(undergrad_locs)\n",
    "\n",
    "# undergrad locations plotting \n",
    "undergrad_map = folium.Map()\n",
    "#Loop through locations and add the markers on the map\n",
    "for undergrad_location in range(len(undergrad_locs)): \n",
    "    folium.Marker([lat_list[undergrad_location], long_list[undergrad_location]],\n",
    "                  popup=undergrad_locs[undergrad_location]).add_to(undergrad_map)\n",
    "    \n",
    "#display map\n",
    "#undergrad_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.3082138, -37.8142176, 52.4775396, 39.9527237, -34.6075616, 55.6828925, 39.9527237, 40.7127281, 25.0375198, 40.7127281, 37.4443293, 45.5202471, 37.8708393, 37.7792808, 35.7006177, 40.4416941, 38.8950092, 52.5170365, 34.0536909, 37.7792808, 42.3602534, 38.9848265, 25.7742658, 40.7127281, 40.4416941]\n",
      "[-72.9250518, 144.9631608, -1.894053, -75.1635262, -58.437076, 37.6223775, -75.1635262, -74.0060152, 121.5636796, -74.0060152, -122.1598465, -122.6741949, -122.2728639, -122.4192363, 51.4013785, -79.9900861, -77.0365625, 13.3888599, -118.2427666, -122.4192363, -71.0582912, -77.0946459, -80.1936589, -74.0060152, -79.9900861]\n",
      "['New Haven, CT, USA', 'Melbourne, Victoria, Australia', 'Birmingham, UK', 'Philadelphia, PA, USA', 'Buenos Aires, Argentina', 'Nagatinskaya, Moscow, Russia', 'Philadelphia, USA', 'New York City, New York, USA', 'Taipei, Taiwan', 'New York, NY', 'Palo Alto, California, USA', 'Portland, OR, USA', 'Berkeley, CA, USA', 'San Francisco, CA, USA', 'Tehran, Tehran, Iran', 'Pittsburgh, PA, USA', 'Washington, DC, US', 'Berlin, Germany', 'Los Angeles, CA, USA', 'San Francisco, CA', 'Boston, MA, USA', 'Bethesda, MD, USA', 'Miami, Florida, USA', 'New York, NY, USA', 'Pittsburgh, PA, USA']\n"
     ]
    }
   ],
   "source": [
    "# Research assistant and lab manager position locations \n",
    "# First create empty structures for your lat and long values\n",
    "lat_list = []\n",
    "long_list = []\n",
    "\n",
    "# Loop through rows to get the longitude and latitude of the RA_locations (be aware of missing data)\n",
    "for research_location in df['ra_lm_loc']:\n",
    "    #print(location_1)\n",
    "    \n",
    "    if pd.isnull(research_location):\n",
    "        lat = None\n",
    "        long = None\n",
    "    else:\n",
    "        location_1 = geolocator.geocode(research_location, timeout=10)\n",
    "        if location_1 is None:\n",
    "            raise ValueError(\"Geocode failed\")\n",
    "        lat = location_1.latitude\n",
    "        long = location_1.longitude\n",
    "    \n",
    "    lat_list.append(lat)\n",
    "    long_list.append(long)\n",
    "    #print((lat,long,research_location))\n",
    "        \n",
    "# #Saving lat and long in separate columns in the dataframe    \n",
    "df['RA_LM_Latitude' ] = lat_list\n",
    "df['RA_LM_Latitude'] = df['RA_LM_Latitude'].astype('float')\n",
    "\n",
    "df['RA_LM_Longitude'] = long_list\n",
    "df['RA_LM_Longitude'] = df['RA_LM_Longitude'].astype('float')\n",
    "#df.head(40)\n",
    "\n",
    "# create a map with research position locations\n",
    "df_research = df.loc[:,\"RA_LM_Latitude\":\"RA_LM_Longitude\"] #create a subset of df to deal with the na problem\n",
    "df_research = df_research.dropna()\n",
    "research_locs = df.loc[:,\"ra_lm_loc\"]\n",
    "#print(df_undergrad)\n",
    "\n",
    "lat_list = list(filter(None, lat_list))\n",
    "long_list = list(filter(None, long_list))\n",
    "research_locs = [x for x in research_locs if pd.notna(x)]\n",
    "\n",
    "# check formats are correct with the NA values removed\n",
    "print(lat_list)\n",
    "print(long_list)\n",
    "print(research_locs)\n",
    "type(research_locs)\n",
    "\n",
    "# research locations plotting \n",
    "research_map = folium.Map()\n",
    "#Loop through locations and add the markers on the map\n",
    "for research_location in range(len(research_locs)): \n",
    "    folium.Marker([lat_list[research_location], long_list[research_location]],\n",
    "                  popup=research_locs[research_location]).add_to(research_map)\n",
    "\n",
    "#display map\n",
    "#research_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PhD position locations \n",
    "# create empty structures\n",
    "lat_list = []\n",
    "long_list = []\n",
    "for phd_location in df['phd_loc']:\n",
    "    #print(location_1)\n",
    "    \n",
    "# Loop through rows to get the longitude and latitude of the RA_locations (be aware of missing data)    \n",
    "    if pd.isnull(phd_location):\n",
    "        lat = None\n",
    "        long = None\n",
    "    else:\n",
    "        location_1 = geolocator.geocode(phd_location, timeout=10)\n",
    "        if location_1 is None:\n",
    "            raise ValueError(\"Geocode failed\")\n",
    "        lat = location_1.latitude\n",
    "        long = location_1.longitude\n",
    "    \n",
    "    lat_list.append(lat)\n",
    "    long_list.append(long)\n",
    "    #print((lat,long,phd_location))\n",
    "        \n",
    "# #Saving lat and long in separate columns in the dataframe    \n",
    "df['PHD_Latitude' ] = lat_list\n",
    "df['PHD_Latitude'] = df['PHD_Latitude'].astype('float')\n",
    "\n",
    "df['PHD_Longitude'] = long_list\n",
    "df['PHD_Longitude'] = df['PHD_Longitude'].astype('float')\n",
    "\n",
    "#create a subset of df to deal with the na problem\n",
    "df_phd = df.loc[:,\"PHD_Latitude\":\"PHD_Longitude\"] \n",
    "df_phd = df_phd.dropna()\n",
    "phd_locs = df.loc[:,\"phd_loc\"]\n",
    "#print(df_undergrad)\n",
    "\n",
    "#remove NA values\n",
    "lat_list = list(filter(None, lat_list))\n",
    "long_list = list(filter(None, long_list))\n",
    "phd_locs = [x for x in phd_locs if pd.notna(x)]\n",
    "\n",
    "# research locations plotting \n",
    "phd_map = folium.Map()\n",
    "#Loop through locations and add the markers on the map\n",
    "for phd_location in range(len(phd_locs)): \n",
    "    folium.Marker([lat_list[phd_location], long_list[phd_location]],\n",
    "                  popup=phd_locs[phd_location]).add_to(phd_map)\n",
    "\n",
    "#display map    \n",
    "#phd_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masters locations \n",
    "lat_list = []\n",
    "long_list = []\n",
    "# Loop through rows to get the longitude and latitude of the PostDoc_locations (be aware of missing data)\n",
    "for masters_location in df['masters_loc']:\n",
    "   \n",
    "    if pd.isnull(masters_location):\n",
    "        lat = None\n",
    "        long = None\n",
    "    else:\n",
    "        location_1 = geolocator.geocode(masters_location, timeout=10)\n",
    "        if location_1 is None:\n",
    "            raise ValueError(\"Geocode failed\")\n",
    "        lat = location_1.latitude\n",
    "        long = location_1.longitude\n",
    "    \n",
    "    lat_list.append(lat)\n",
    "    long_list.append(long)\n",
    "    #print((lat,long,masters_location))\n",
    "        \n",
    "# #Saving lat and long in separate columns in the dataframe    \n",
    "df['Masters_Latitude' ] = lat_list\n",
    "df['Masters_Latitude'] = df['Masters_Latitude'].astype('float')\n",
    "\n",
    "df['Masters_Longitude'] = long_list\n",
    "df['Masters_Longitude'] = df['Masters_Longitude'].astype('float')\n",
    "#df.head(40)\n",
    "\n",
    "# create a map with research position locations\n",
    "df_masters = df.loc[:,\"Masters_Latitude\":\"Masters_Longitude\"] #create a subset of df to deal with the na problem\n",
    "df_masters = df_masters.dropna()\n",
    "masters_locs = df.loc[:,\"masters_loc\"]\n",
    "#print(df_undergrad)\n",
    "\n",
    "lat_list = list(filter(None, lat_list))\n",
    "long_list = list(filter(None, long_list))\n",
    "masters_locs = [x for x in masters_locs if pd.notna(x)]\n",
    "\n",
    "# research locations plotting \n",
    "masters_map = folium.Map()\n",
    "#Loop through locations and add the markers on the map\n",
    "for masters_location in range(len(masters_locs)): \n",
    "    folium.Marker([lat_list[masters_location], long_list[masters_location]],\n",
    "                  popup=masters_locs[masters_location]).add_to(masters_map)\n",
    "\n",
    "#display map    \n",
    "#masters_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post Doc locations \n",
    "lat_list = []\n",
    "long_list = []\n",
    "# Loop through rows to get the longitude and latitude of the PostDoc_locations (be aware of missing data)\n",
    "for postdoc_location in df['postdoc_loc']:\n",
    "   \n",
    "    if pd.isnull(postdoc_location):\n",
    "        lat = None\n",
    "        long = None\n",
    "    else:\n",
    "        location_1 = geolocator.geocode(postdoc_location, timeout=10)\n",
    "        if location_1 is None:\n",
    "            raise ValueError(\"Geocode failed\")\n",
    "        lat = location_1.latitude\n",
    "        long = location_1.longitude\n",
    "    \n",
    "    lat_list.append(lat)\n",
    "    long_list.append(long)\n",
    "    #print((lat,long,postdoc_location))\n",
    "        \n",
    "# #Saving lat and long in separate columns in the dataframe    \n",
    "df['PostDoc_Latitude' ] = lat_list\n",
    "df['PostDoc_Latitude'] = df['PostDoc_Latitude'].astype('float')\n",
    "\n",
    "df['PostDoc_Longitude'] = long_list\n",
    "df['PostDoc_Longitude'] = df['PostDoc_Longitude'].astype('float')\n",
    "#df.head(40)\n",
    "\n",
    "# create a map with research position locations\n",
    "df_postdoc = df.loc[:,\"PostDoc_Latitude\":\"PostDoc_Longitude\"] #create a subset of df to deal with the na problem\n",
    "df_postdoc = df_postdoc.dropna()\n",
    "postdoc_locs = df.loc[:,\"postdoc_loc\"]\n",
    "#print(df_undergrad)\n",
    "\n",
    "lat_list = list(filter(None, lat_list))\n",
    "long_list = list(filter(None, long_list))\n",
    "postdoc_locs = [x for x in postdoc_locs if pd.notna(x)]\n",
    "\n",
    "# research locations plotting \n",
    "postdoc_map = folium.Map()\n",
    "#Loop through locations and add the markers on the map\n",
    "for postdoc_location in range(len(postdoc_locs)): \n",
    "    folium.Marker([lat_list[postdoc_location], long_list[postdoc_location]],\n",
    "                  popup=postdoc_locs[postdoc_location]).add_to(postdoc_map)\n",
    "\n",
    "#display map    \n",
    "#postdoc_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with just lat and long info \n",
    "loc_df = df.loc[:,'HometownLatitude':'PostDoc_Longitude']\n",
    "# View the dataframe \n",
    "#loc_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Faculty locations \n",
    "lat_list = []\n",
    "long_list = []\n",
    "# Loop through rows to get the longitude and latitude of the PostDoc_locations (be aware of missing data)\n",
    "for faculty_location in df['faculty_loc']:\n",
    "   \n",
    "    if pd.isnull(faculty_location):\n",
    "        lat = None\n",
    "        long = None\n",
    "    else:\n",
    "        location_1 = geolocator.geocode(faculty_location, timeout=10)\n",
    "        if location_1 is None:\n",
    "            raise ValueError(\"Geocode failed\")\n",
    "        lat = location_1.latitude\n",
    "        long = location_1.longitude\n",
    "    \n",
    "    lat_list.append(lat)\n",
    "    long_list.append(long)\n",
    "    #print((lat,long,faculty_location))\n",
    "        \n",
    "# #Saving lat and long in separate columns in the dataframe    \n",
    "df['Faculty_Latitude' ] = lat_list\n",
    "df['Faculty_Latitude'] = df['Faculty_Latitude'].astype('float')\n",
    "\n",
    "df['Faculty_Longitude'] = long_list\n",
    "df['Faculty_Longitude'] = df['Faculty_Longitude'].astype('float')\n",
    "#df.head(40)\n",
    "\n",
    "# create a map with research position locations\n",
    "df_faculty = df.loc[:,\"Faculty_Longitude\":\"Faculty_Latitude\"] #create a subset of df to deal with the na problem\n",
    "df_faculty = df_faculty.dropna()\n",
    "faculty_locs = df.loc[:,\"faculty_loc\"]\n",
    "#print(df_undergrad)\n",
    "\n",
    "lat_list = list(filter(None, lat_list))\n",
    "long_list = list(filter(None, long_list))\n",
    "faculty_locs = [x for x in faculty_locs if pd.notna(x)]\n",
    "\n",
    "# research locations plotting \n",
    "faculty_map = folium.Map()\n",
    "#Loop through locations and add the markers on the map\n",
    "for faculty_location in range(len(faculty_locs)): \n",
    "    folium.Marker([lat_list[faculty_location], long_list[faculty_location]],\n",
    "                  popup=faculty_locs[faculty_location]).add_to(faculty_map)\n",
    "\n",
    "#display map    \n",
    "#faculty_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear color gradiations \n",
    "import matplotlib.pyplot as plt\n",
    "rgba = plt.cm.autumn_r(np.linspace(0,1,7))\n",
    "rgbb = plt.cm.winter_r(np.linspace(0,1,7))\n",
    "\n",
    "rgb = rgbb[:, :3]\n",
    "rgb255 = rgb * 255\n",
    "rgb255 = rgb255.astype(int)\n",
    "color = \"rgb(%s, %s, %s)\" % (rgb255[0][0], rgb255[0][1], rgb255[0][2])\n",
    "color_1 = \"rgb(%s, %s, %s)\" % (rgb255[1][0], rgb255[1][1], rgb255[1][2])\n",
    "color_2 = \"rgb(%s, %s, %s)\" % (rgb255[2][0], rgb255[2][1], rgb255[2][2])\n",
    "color_3 = \"rgb(%s, %s, %s)\" % (rgb255[3][0], rgb255[3][1], rgb255[3][2])\n",
    "color_4 = \"rgb(%s, %s, %s)\" % (rgb255[4][0], rgb255[5][1], rgb255[4][2])\n",
    "color_5 = \"rgb(%s, %s, %s)\" % (rgb255[5][0], rgb255[5][1], rgb255[5][2])\n",
    "color_6 = \"rgb(%s, %s, %s)\" % (rgb255[6][0], rgb255[6][1], rgb255[6][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9769ade9629e454784c149cb4a80587a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(basemap={'url': 'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', 'max_zoom': 19, 'attribution': 'Map …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = Map(zoom=1, fitWorld=True)\n",
    "rad = 10\n",
    "#var circle = L.circle([click.lat, click.lng], 50000).addTo(map);\n",
    "\n",
    "# hometown\n",
    "hometown = []\n",
    "for ii in range(len(locs)):\n",
    "    coords = df.HometownLatitude[ii],df.HometownLongitude[ii]\n",
    "    c = Circle()\n",
    "    c.radius = 5\n",
    "    c.location = coords\n",
    "    c.color = \"red\"\n",
    "    c.fill = True\n",
    "    c.name = \"Hometown location\"\n",
    "    hometown.append(c)\n",
    "    ht_loc = HTML()\n",
    "    ht_loc.value = locs[ii]\n",
    "    c.popup = ht_loc\n",
    "ht = lf.LayerGroup(name='hometown', layers=hometown)\n",
    "m.add_layer(ht)\n",
    "\n",
    "    \n",
    "#ensure NA's are removed and turn undergrad_locs back into series  \n",
    "undergrad_locs = [x for x in undergrad_locs if pd.notna(x)]\n",
    "undergrad_locs = pd.Series(undergrad_locs)  \n",
    "# undergrad\n",
    "undergrad = []\n",
    "for ii in range(len(undergrad_locs)):\n",
    "    coords = df_undergrad.UndergradLatitude.iloc[ii],df_undergrad.UndergradLongitude.iloc[ii]\n",
    "    c = Circle()\n",
    "    c.radius = rad\n",
    "    c.location = coords\n",
    "    c.color = \"purple\"\n",
    "    c.fill = True\n",
    "    c.name = \"Undergrad location\"\n",
    "    undergrad.append(c)\n",
    "    underg_loc = HTML()\n",
    "    underg_loc.value = undergrad_locs[ii]\n",
    "    c.popup = underg_loc\n",
    "ug = lf.LayerGroup(name='undergrad', layers=undergrad)\n",
    "m.add_layer(ug)\n",
    "\n",
    "#ensure NA's are removed and turn research_locs back into series \n",
    "research_locs = [x for x in research_locs if pd.notna(x)]\n",
    "research_locs = pd.Series(research_locs) \n",
    "# research positions\n",
    "research = []\n",
    "for ii in range(len(research_locs)):\n",
    "    coords = df_research.RA_LM_Latitude.iloc[ii],df_research.RA_LM_Longitude.iloc[ii]\n",
    "    c = Circle()\n",
    "    c.radius = rad\n",
    "    c.location = coords\n",
    "    c.color = \"pink\"\n",
    "    c.fill = True\n",
    "    c.name = \"RA location\"\n",
    "    research.append(c)\n",
    "    research_loc = HTML()\n",
    "    research_loc.value = undergrad_locs[ii]\n",
    "    c.popup = research_loc\n",
    "ra = lf.LayerGroup(name='research', layers=research)\n",
    "m.add_layer(ra)\n",
    "    \n",
    "#ensure NA's are removed and turn research_locs back into series \n",
    "masters_locs = [x for x in masters_locs if pd.notna(x)]\n",
    "masters_locs = pd.Series(masters_locs)     \n",
    "# master\n",
    "master = []\n",
    "for ii in range(len(masters_locs)):\n",
    "    coords = df.Masters_Latitude.iloc[ii],df.Masters_Longitude.iloc[ii]\n",
    "    c = Circle()\n",
    "    c.radius = rad\n",
    "    c.location = coords\n",
    "    c.color = color\n",
    "    c.fill = True\n",
    "    c.name = \"Master location\"\n",
    "    master.append(c)\n",
    "    master_loc = HTML()\n",
    "    master_loc.value = masters_locs[ii] \n",
    "    c.popup = master_loc\n",
    "ms = lf.LayerGroup(name='master', layers=master)\n",
    "m.add_layer(ms)\n",
    "\n",
    "    \n",
    "#ensure NA's are removed and turn phd_locs back into series \n",
    "phd_locs = [x for x in phd_locs if pd.notna(x)]\n",
    "phd_locs = pd.Series(phd_locs)\n",
    "# ensure df_phd is made without NA\n",
    "df_phd = df.loc[:,\"PHD_Latitude\":\"PHD_Longitude\"] \n",
    "df_phd = df_phd.dropna()\n",
    "# phd\n",
    "phd = []\n",
    "for ii in range(len(phd_locs)):\n",
    "    coords = df_phd.PHD_Latitude.iloc[ii],df_phd.PHD_Longitude.iloc[ii]\n",
    "    c = Circle()\n",
    "    c.radius = rad\n",
    "    c.location = coords\n",
    "    c.color = color_4\n",
    "    c.fill = True\n",
    "    c.name = \"PhD location\"\n",
    "    phd.append(c)\n",
    "    phd_loc = HTML()\n",
    "    phd_loc.value = phd_locs[ii]\n",
    "    c.popup = phd_loc\n",
    "ph = lf.LayerGroup(name='phd', layers=phd) \n",
    "m.add_layer(ph)\n",
    "\n",
    "#ensure NA's are removed and turn postdoc_locs back into series \n",
    "postdoc_locs = [x for x in postdoc_locs if pd.notna(x)]\n",
    "postdoc_locs = pd.Series(postdoc_locs) \n",
    "# ensure df_phd is made without NA\n",
    "df_postdoc = df.loc[:,\"PostDoc_Latitude\":\"PostDoc_Longitude\"] \n",
    "df_postdoc = df_postdoc.dropna()\n",
    "# postdoc\n",
    "postdoc = []\n",
    "for ii in range(len(postdoc_locs)):\n",
    "    coords = df_postdoc.PostDoc_Latitude.iloc[ii],df_postdoc.PostDoc_Longitude.iloc[ii]\n",
    "    c = Circle()\n",
    "    c.radius = rad\n",
    "    c.location = coords\n",
    "    c.color = \"orange\"\n",
    "    c.fill = True\n",
    "    c.name = \"Postdoc location\"\n",
    "    postdoc.append(c)\n",
    "    postdoc_loc = HTML()\n",
    "    postdoc_loc.value = phd_locs[ii] \n",
    "    c.popup = postdoc_loc\n",
    "m.add_layer(psd)\n",
    "psd = lf.LayerGroup(name='postdoc', layers=postdoc)\n",
    "\n",
    "#ensure NA's are removed and turn faculty_locs back into series     \n",
    "faculty_locs = [x for x in faculty_locs if pd.notna(x)]\n",
    "faculty_locs = pd.Series(faculty_locs)\n",
    "\n",
    "# ensure df_faculty is made without NA\n",
    "df_faculty = df.loc[:,\"Faculty_Latitude\":\"Faculty_Longitude\"] \n",
    "df_faculty = df_faculty.dropna()\n",
    "# faculty\n",
    "faculty = []\n",
    "for ii in range(len(faculty_locs)):\n",
    "    coords = df_faculty.Faculty_Latitude.iloc[ii],df_faculty.Faculty_Longitude.iloc[ii]\n",
    "    c = Circle()\n",
    "    c.radius = rad\n",
    "    c.location = coords\n",
    "    c.color = \"brown\"\n",
    "    c.fill = True\n",
    "    c.name = \"Faculty location\"\n",
    "    faculty.append(c)\n",
    "    faculty_loc = HTML()\n",
    "    faculty_loc.value = faculty_locs[ii]\n",
    "    c.popup = faculty_loc\n",
    "fc = lf.LayerGroup(name='faculty', layers=faculty)\n",
    "m.add_layer(fc)\n",
    "\n",
    "\n",
    "zoom_slider = IntSlider(description='Zoom level:', min=0, max=15, value=2)\n",
    "jslink((zoom_slider, 'value'), (m, 'zoom'))\n",
    "widget_control1 = WidgetControl(widget=zoom_slider, position='topright')\n",
    "m.add_control(widget_control1)\n",
    "\n",
    "m.add_control(FullScreenControl())\n",
    "m.add_control(LayersControl())\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51.45149525, -0.983634249936538)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_postdoc.PostDoc_Latitude.iloc[1],df_postdoc.PostDoc_Longitude.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             London, Ontario, Canada\n",
      "1                         Reading, UK\n",
      "2        New Haven, CT, United States\n",
      "3                        Perm, Russia\n",
      "4                Los Angeles, CA, USA\n",
      "5     Philadelphia, PA, United States\n",
      "6                            York, UK\n",
      "7                       New Haven, CT\n",
      "8               Davis, California, US\n",
      "9         Minneapolis, Minnesota, USA\n",
      "10                   Boulder, CO, USA\n",
      "11            London, Ontario, Canada\n",
      "12                  Berkeley, CA, USA\n",
      "13                        Seattle, WA\n",
      "14                  Berkeley, CA, USA\n",
      "15                     Boston, MA, US\n",
      "16           Toronto, Ontario, Canada\n",
      "17                  Stanford, CA, USA\n",
      "18                   Boston, MA . USA\n",
      "19             San Francisco, CA, USA\n",
      "20                      Cambridge, UK\n",
      "21                 Austin, Texas, USA\n",
      "22            Leiden, the Netherlands\n",
      "23          Berkeley, California, USA\n",
      "24                 Cambridge, MA, USA\n",
      "25                            Ireland\n",
      "26         Princeton, New Jersey, USA\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# postdoc_locs = df.loc[:,\"postdoc_loc\"]\n",
    "# postdoc_locs = [x for x in postdoc_locs if pd.notna(x)]\n",
    "# postdoc_locs = pd.Series(postdoc_locs) \n",
    "# # ensure df_phd is made without NA\n",
    "# df_postdoc = df.loc[:,\"PostDoc_Latitude\":\"PostDoc_Longitude\"] \n",
    "# df_postdoc = df_postdoc.dropna()\n",
    "# len(df_postdoc)\n",
    "# print(postdoc_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
